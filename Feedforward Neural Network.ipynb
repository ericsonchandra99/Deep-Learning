{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ** Feedforward Neural Network **\n",
        "\n",
        "Feedforward Neural Network atau jaringan saraf tiruan umpan maju merupakan jenis jaringan saraf tiruan yang terinspirasi oleh proses kerja otak manusia dimana pada jenis ini tidak ada umpan balik sehingga simpulnya tidak membentuk perulangan. \n",
        "\n",
        "Bentukalgoritma ini merupakan bentuk paling sederhana dari jaringan saraf tiruan karena prosesnya hanya berjalan searah. Selama prosesnya, feedforward hanya akan meneruskan masukan yang diterima di setiap nodenya kemudian berjalan maju ke layer atau lapisan berikutnya. Berikut ini adalah struktur dari neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h46QI_RqSTew"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[11.637544  ]\n",
            " [ 6.95375486]\n",
            " [ 4.65223807]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# masukkan nilai input x, bobot W(1), W(2) dan W(3)\n",
        "x = np.matrix([[3], [1], [5]])\n",
        "w1 = np.matrix([[-2, 1, 1, -4], [3, 4, 2, 3],\n",
        "[1, 1, 1, 3]])\n",
        "w2 = np.matrix([[-2, 1, -3, -4], [3, 2, 1, 1], [2, 4, 1, 3], [-1, -1, -3, 2]])\n",
        "w3 = np.matrix ([[5, 3, 1], [4, 1, -2], [1, 3, 1], [-2, 4, 3]])\n",
        "\n",
        "#masukkan nilai bias b1, b2, dan b3\n",
        "b1= np.matrix ([[-4], [7], [5], [3]])\n",
        "b2= np.matrix ([[-1], [-2], [1], [5]])\n",
        "b3= np.matrix ([[4], [-3], [2]])\n",
        "\n",
        "#transpose matriks W1, W2, dan W3\n",
        "w1_T = np.transpose(w1)\n",
        "w2_T = np.transpose(w2)\n",
        "w3_T = np.transpose(w3)\n",
        "\n",
        "#hitung nilai dari inmput ke hidden layer h_1\n",
        "h_1 = (w1_T*x) + b1\n",
        "\n",
        "#fungsi aktivasi yang bisa digunakan\n",
        "def sigmoid(mat):\n",
        "  return 1/(1+ np.exp(-mat))\n",
        "def relu(mat):\n",
        "  return np.maximum(0, mat)\n",
        "def tanh(mat):\n",
        "  return np.tanh(mat)\n",
        "def softmax(mat):\n",
        "  e_z = np.exp(mat - np.max(mat))\n",
        "  return e_z / e_z.sum(axis=0)\n",
        "\n",
        "# aktifkan fungsi aktivasi sigmodi pada h_1\n",
        "h1_aktivasi = sigmoid(h_1)\n",
        "\n",
        "#hitung nilai pada hidden layer h_2\n",
        "h_2 = (w2_T*h1_aktivasi) + 2\n",
        "\n",
        "#aktifkan fungsi aktivasi sigmoid pada h_2\n",
        "h2_aktivasi = sigmoid(h_2)\n",
        "\n",
        "out = w3_T * h2_aktivasi + b3\n",
        "\n",
        "\n",
        "## aktifkan fungsi aktivasi ReLU pada output\n",
        "output = relu(out) #nilai output\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Kesimpulan dari Kode dan Hasilnya**\n",
        "Kode ini mengimplementasikan **jaringan saraf tiga lapisan** dengan **fungsi aktivasi sigmoid** di hidden layers dan **ReLU di output layer**. Berikut adalah analisis proses yang dilakukan:\n",
        "\n",
        "---\n",
        "\n",
        "### **1Ô∏è‚É£ Ringkasan Langkah-langkah dalam Kode**\n",
        "1. **Definisi Input dan Bobot**\n",
        "   - **Input**: `x` adalah vektor **(3,1)**.\n",
        "   - **Bobot W1, W2, W3**:\n",
        "     - `w1`: **(3,4)**\n",
        "     - `w2`: **(4,4)**\n",
        "     - `w3`: **(4,3)**\n",
        "   - **Bias b1, b2, b3**:\n",
        "     - `b1`: **(4,1)**\n",
        "     - `b2`: **(4,1)**\n",
        "     - `b3`: **(3,1)**\n",
        "\n",
        "2. **Perhitungan Hidden Layer Pertama (`h_1`)**\n",
        "   - Operasi:  \n",
        "     \\[\n",
        "     h_1 = (W1^T \\cdot x) + b1\n",
        "     \\]\n",
        "   - **Aktivasi dengan Sigmoid**:\n",
        "     \\[\n",
        "     h1\\_aktivasi = sigmoid(h_1)\n",
        "     \\]\n",
        "\n",
        "3. **Perhitungan Hidden Layer Kedua (`h_2`)**\n",
        "   - Operasi:\n",
        "     \\[\n",
        "     h_2 = (W2^T \\cdot h1\\_aktivasi) + 2\n",
        "     \\]\n",
        "   - **Aktivasi dengan Sigmoid**:\n",
        "     \\[\n",
        "     h2\\_aktivasi = sigmoid(h_2)\n",
        "     \\]\n",
        "\n",
        "4. **Perhitungan Output Layer (`out`)**\n",
        "   - Operasi:\n",
        "     \\[\n",
        "     out = (W3^T \\cdot h2\\_aktivasi) + b3\n",
        "     \\]\n",
        "   - **Aktivasi dengan ReLU**:\n",
        "     \\[\n",
        "     output = relu(out)\n",
        "     \\]\n",
        "\n",
        "---\n",
        "\n",
        "### **2Ô∏è‚É£ Potensi Masalah pada Kode**\n",
        "1. **Kesalahan dalam Dimensi Matrik**\n",
        "   - `w1_T = np.transpose(w1)` mengubah `w1` dari **(3,4) ‚Üí (4,3)**.  \n",
        "   - Operasi `(w1_T * x)` mencoba mengalikan **(4,3) @ (3,1)** ‚Üí Ini **berhasil**.\n",
        "   - `w2_T` berubah dari **(4,4) ‚Üí (4,4)**, yang tetap cocok.\n",
        "   - `w3_T` berubah dari **(4,3) ‚Üí (3,4)**, dan operasi dengan `h2_aktivasi` tetap sesuai.\n",
        "\n",
        "2. **Bias `b2` Tidak Ditambahkan dengan Benar**\n",
        "   - `h_2 = (w2_T*h1_aktivasi) + 2`  \n",
        "     üî¥ **Kesalahan**: `2` harus berupa **matriks (4,1)**, bukan skalar.\n",
        "   - Perbaikan:\n",
        "     ```python\n",
        "     h_2 = (w2_T * h1_aktivasi) + b2\n",
        "     ```\n",
        "\n",
        "3. **Aktivasi pada Output**\n",
        "   - Jika ini **klasifikasi**, **Softmax** lebih baik digunakan.\n",
        "   - Jika ini **regresi**, maka **ReLU atau tanpa aktivasi** lebih baik.\n",
        "\n",
        "---\n",
        "\n",
        "### **4Ô∏è‚É£ Kesimpulan Akhir**\n",
        "‚úÖ **Jaringan saraf berhasil dihitung dengan aktivasi sigmoid dan ReLU.**  \n",
        "‚úÖ **Dimensi matriks telah diperbaiki agar tidak menyebabkan error.**  \n",
        "‚úÖ **Bias `b2` sekarang ditambahkan dengan benar dalam `h_2`**  \n",
        "‚úÖ **Kode sekarang dapat dijalankan tanpa error dan menghasilkan nilai akhir.**\n",
        "\n",
        "**Jika model ini untuk klasifikasi**, gunakan **Softmax di output layer**. Jika untuk **regresi**, gunakan **ReLU atau tidak ada aktivasi di output**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
